\section[Practice: Probability Refresher II]{Practice: Probability Refresher II \iftoggle{showdates}{\small{\textit{2014-05-05}}}{}}
\subsection*{Exercise 1}
There are different types of roulette, we will only deal with the so-called 
``European'' one, which features only one $0$, no $00$.

The sample space $\Omega$ is $\Omega=\left\{0, 1, 2, 3, ..., 36\right\}$. The event space is $\mathcal{P} \left( \Omega \right) \setminus \Omega$, the number of events $2^{|\Omega|} = 2^37 = 2^10 * 2^10 * 2^10 * 2^7 \approx 128,000,000,000 (128 Bio)$.

The expected values are:
\begin{align*}
E(even) &= 18 \cdot \frac{18}{37} - 18 \cdot \frac{19}{37} = -0.49\\
E(even\ numbers) &= \left(35 \cdot \frac{1}{37} - 1 \cdot \frac{36}{37} \right) * 18 = -0.49
\end{align*}
So basically both variants are the same. 

However, in European roulette there usually exists the so-called ``en prison''-rule. This rule freezes (``imprisons'') the stakes made on the small bets (``odd'', ``even'', ``red'', ``black'', ``high'', ``low'') after a $0$ until the specific bet was fulfilled twice in a row. When it came up twice in a row, you are allowed to get your stakes back. Alternatively, if you want to play with your bets, you can keep half of them instead of letting them being frozen, losing the other half. This modifies the expected value:

\begin{align*}
E(even, 0, freeze) &= 18 \cdot \frac{18}{37} - 18 \cdot \frac{18}{37} - 0 \cdot \frac{1}{37} = 0  \\
E(even, 0, return) &= 18 \cdot \frac{18}{37} - 18 \cdot \frac{18}{37} - 9 \cdot \frac{1}{37} = -0.24  \\
E(even, 0) &= \frac{1}{2} \left( E(even, 0, return) + E(even, 0, freeze) \right) = -0.12 \\
E(even) &= \frac{\frac{1}{37} E(even, 0) + \frac{36}{37} E(even, \neg 0)}{2} = -0.48
\end{align*}

With the ``en prison'' rule betting on ``even'' is therefore better than betting on all even numbers.

\noindent {}

The Bank makes money because of the $0$: For calculating the odds they assume not 37 but 36 numbers.


\subsection*{Exercise 2}
The union-bound can be proved by induction.

\noindent $Basis:$ \\ For $n=1$ we have
\setcounter{equation}{0}
\begin{align}
& & P(\bigcup_{i=1}^{1}(E_i)) & \leq \sum_{i=1}^{1}(P(E_i)) & & \\
\Leftrightarrow & & P(E_1) & = P(E_1) & & 
\end{align}

\noindent $Inductive Step:$ \\
We know that $P(A \cup B) = P(A) + P(B) - P(A \cap B)$, so it follows that:
\begin{align}
& & P(\bigcup_{i=1}^{n+1}(E_i)) & = P(\bigcup_{i=1}^{n}(E_i)) + P(E_{n+1}) - P(\bigcup_{i=1}^{n}(E_i) \cap E_{n+1}) & &
\end{align}

\noindent Now since $P(\bigcup_{i=1}^{n}(E_i) \cap E_{n+1})$ is a probability, by the first axiom of probability we know that it is bigger or equal to zero:
\begin{align}
 P(\bigcup_{i=1}^{n}(E_i) \cap E_{n+1}) \geq 0 
\end{align}

\noindent By adding it to both sides of the inequality we get:
\begin{align}
& & P(\bigcup_{i=1}^{n+1}(E_i)) + P(\bigcup_{i=1}^{n}(E_i) \cap E_{n+1}) & = P(\bigcup_{i=1}^{n}(E_i)) + P(E_{n+1})  & &
\end{align}

\noindent And therefore we know:
\begin{align}
& & P(\bigcup_{i=1}^{n+1}(E_i)) \leq P(\bigcup_{i=1}^{n}(E_i)) + P(E_{n+1})  & &
\end{align}

\noindent This is equvialent to:
\begin{align}
& & P(\bigcup_{i=1}^{n+1}(E_i)) \leq \sum_{i=1}^{n}(P(E_i) + P(E_{n+1})) & = \sum_{i=1}^{n+1}(P(E_i)) & &
\end{align}
\setcounter{equation}{0}


\subsection*{Exercise 3}
\begin{align*}
P(A|B) & = \frac{P(B|A) \cdot P(A)}{P(B)} \\
Posterior & = \frac{Likelihood \cdot Prior}{Evidence}
\end{align*}

\begin{align*}
\frac{P(A|B)}{P(not A|B)} & = \frac{P(B|A)}{P(B|not A)} \cdot \frac{P(A)}{P(not A)} \\
Posterior & = Likelihoodratio \cdot Prior
\end{align*}


\subsection*{Exercise 4}

We take Bayes' rule to calculate $P(\mbox{Blue Car}|\mbox{Testified by Witness})$
\begin{align*}
P(B|T) = \frac{P(T|B) \cdot P(B)}{P(T)}
\end{align*}
We know that $P(T|B) = 0.8$ and $P(B) = 0.15$, so we only have to find out $P(T)$. Therefore we marginalize over B:
\begin{align*}
\sum_{B}{P(T|B) \cdot P(B)} = 0.8 \cdot 0.15 + 0.2 \cdot 0.85 = 0.29
\end{align*}
Now we can take our values and calculate the correct answer:
\begin{align*}
P(B|T) = \frac{P(T|B) \cdot P(B)}{P(T)} = \frac{0.8 \cdot 0.15}{0.29} = 0.414
\end{align*}
\\
When testing a large group of people is asked, the common mistake becomes obvious that they take the probability that the witness correctly identified each one of the two colors, which is 80\%, as the probability that is asked for.

\setcounter{equation}{0}
\subsection*{Exercise 5}

We take Bayes' rule to calculate $P(\mbox{Cancer}|\mbox{Positive Test})$
\begin{align*}
P(C|P) = \frac{P(P|C) \cdot P(C)}{P(P)}
\end{align*}
We know that $P(P|C) = 0.5$ and $P(C) = 0.003$, so we only have to find out $P(P)$. Therefore we marginalize over C:
\begin{align*}
\sum_{C}{P(P|C) \cdot P(C)} = 0.5 \cdot 0.003 + 0.03 \cdot 0.997 = 0.0314
\end{align*}
Now we can take our values and calculate the correct answer:
\begin{align*}
P(C|P) = \frac{P(P|C) \cdot P(C)}{P(P)} = \frac{0.5 \cdot 0.003}{0.0314} = 0.048
\end{align*}

As we can see, only 4.8\% of the people being tested positively actually have cancer. Nevertheless screening is a good thing because out of 1000 detections still 50 have cancer and those can be treated which probably makes up for the disadvantage of having 950 false alarms.  

\setcounter{equation}{0}
\subsection*{Exercise 6}

\begin{tabular}{ r|c|c|l }
\multicolumn{1}{r}{}
 &  \multicolumn{1}{c}{Cancer}
 & \multicolumn{1}{c}{$\neg$ Cancer} \\
\cline{2-3}
Positive Test & 0.15\% & 2.99\% & 3.14\%\\ 
\cline{2-3}
Negative Test & 0.15\% & 96.71\% & 96.86\% \\
\cline{2-3}
\multicolumn{1}{r}{}
 &  \multicolumn{1}{c}{0.3\%}
 & \multicolumn{1}{c}{99.7\%}  & \multicolumn{1}{c}{100\%}\\
\end{tabular}

\begin{align*}
& P(P) = \sum_{C}{P(P|C) \cdot P(C)} = 0.5 \cdot 0.003 + 0.03 \cdot 0.997 = 0.0314\\
& P(\neg P) = \sum_{C}{P(\neg P|C) \cdot P(C)} = 0.5 \cdot 0.003 + 0.97 \cdot 0.997 = 0.9686\\ 
& P(P|C) = \frac{P(P,C)}{P(C)} = \frac{0.0015}{0.003} = 0.5 \\
& P(P|\neg C) = \frac{P(P,\neg C)}{P(\neg C)} = \frac{0.0299}{0.997} = 0.03 \\
& P(\neg P|C) = \frac{P(\neg P,C)}{P(C)} = \frac{0.0015}{0.003} = 0.5 \\
& P(\neg P|\neg C) = \frac{P(\neg P,\neg C)}{P(\neg C)} = \frac{0.9671}{0.997}= 0.97\\
& P(C|P) = \frac{P(C,P)}{P(P)} = \frac{0.0015}{0.0314} = 0.048 \\
& P(C|\neg P) = \frac{P(C,\neg P)}{P(\neg P)} = \frac{0.0015}{0.9686} = 0.002 \\
& P(\neg C|P) = \frac{P(\neg C,P)}{P(P)} = \frac{0.0299}{0.0314} = 0.952 \\
& P(\neg C|\neg P) = \frac{P(\neg C,\neg P)}{P(\neg P)} = \frac{0.9671}{0.9686}= 0.998 
\end{align*}

If the events were independent but $P(C)=0.003$, $P(\neg C)=0.997$, $P(P)=0.0314$ and $P(\neg P)=0.9686$ stay as they are, we would get:

\begin{tabular}{ r|c|c|l }
\multicolumn{1}{r}{}
 &  \multicolumn{1}{c}{Cancer}
 & \multicolumn{1}{c}{$\neg$ Cancer} \\
\cline{2-3}
Positive Test & 0.009\% & 3.131\% & 3.14\%\\ 
\cline{2-3}
Negative Test & 0.291\% & 96.569\% & 96.86\% \\
\cline{2-3}
\multicolumn{1}{r}{}
 &  \multicolumn{1}{c}{0.3\%}
 & \multicolumn{1}{c}{99.7\%}  & \multicolumn{1}{c}{100\%}\\
\end{tabular}
\newpage
The conditional probabilities change as follows:
\begin{align*}
& P(P|C) = \frac{P(P,C)}{P(C)} = \frac{0.00009}{0.003} = 0.03 \\
& P(P|\neg C) = \frac{P(P,\neg C)}{P(\neg C)} = \frac{0.03131}{0.997} = 0.0314 \\
& P(\neg P|C) = \frac{P(\neg P,C)}{P(C)} = \frac{0.00291}{0.003} = 0.97 \\
& P(\neg P|\neg C) = \frac{P(\neg P,\neg C)}{P(\neg C)} = \frac{0.96569}{0.997}= 0.9686\\
& P(C|P) = \frac{P(C,P)}{P(P)} = \frac{0.00009}{0.0314} = 0.00287 \\
& P(C|\neg P) = \frac{P(C,\neg P)}{P(\neg P)} = \frac{0.00291}{0.9686} = 0.003 \\
& P(\neg C|P) = \frac{P(\neg C,P)}{P(P)} = \frac{0.03131}{0.0314} = 0.99713 \\
& P(\neg C|\neg P) = \frac{P(\neg C,\neg P)}{P(\neg P)} = \frac{0.96569}{0.9686}= 0.997 
\end{align*}

\subsection*{Exercise 7}

As the probability for each door to contain a car is equal we know that our chance to win is given by $P(\mbox{Win}) = \frac{1} 3$\\
Further the probability that the Quiz-master chooses one of the remaining doors is
$P(\mbox{Open}) = \frac{1} 2$\\
The Quiz-master would not open the door which contains the car so: \\
$P(\mbox{notOpen}|\mbox{Win}) = 1$\\
Now if calculate the probability of the car being behind the not opened door using Bayes' we get:
\begin{align*}
& & P(Win|notOpen) & = \frac{P(notOpen|Win) \cdot P(Win)}{P(notOpen)} & = \frac{1 \cdot \frac{1}{3}}{\frac{1}{2}} &= \frac{2}{3}& &
\end{align*}
\\
Therefore the probability that the car is behind the door that the Quiz-master did not open is $\frac{2}{3}$ while the probability of our first chosen door still is $\frac{1}{3}$. So we would double our chances to win by changing our choice.