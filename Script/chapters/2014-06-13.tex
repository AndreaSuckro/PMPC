\documentclass[../main/Notes.tex]{subfiles}
\begin{document}

\section[Signal Detection Theory I]{Signal Detection Theory I \iftoggle{showdates}{\small{\textit{2014-06-13}}}{}}

\subsection{Detection tasks}

Detection tasks are simple yes/no response tasks -- is there a signal or is there no signal -- the difficulty of such a task stems from the fact that there is always noise in the system, so we can't be sure whether or not your answer is correct.

\paragraph{Examples}
\begin{itemize}
\item Binary signal transmission over noise channel (cable, radio)
\item Information retrieval
\item airport security scans (is this a weapon or just a hair dryer)
\end{itemize}

\setlength{\extrarowheight}{.2cm}
\begin{tabular}{ c|c|c|}
  \backslashbox{\small Result}{\small Signal}       & \multicolumn{1}{c}{S = yes}   & \multicolumn{1}{c}{S = no} \\ \hline
  \multicolumn{1}{l|}{R = yes}	& Hits      & False Alarms          \\ \hline
\multicolumn{1}{l|}{R = no}  & Misses    & Correct Rejections    \\ \hline
\end{tabular}

\paragraph{Response strategy}

\begin{figure}[!ht]
\centering
\begin{tikzpicture}
  \begin{axis}[axis x line*=bottom, axis y line*=left, enlargelimits=upper, axis on top, domain=0:1, legend style={at={(1.2,0.8)}, anchor=east}]
  \addplot[smooth] file {../data/2014-06-13_dist1.txt};
  \addlegendentry{P(X|S=yes)}
  \addplot[smooth, dashed] file {../data/2014-06-13_dist2.txt};
  \addlegendentry{P(X|S=no)}
  \addplot[smooth] file {../data/2014-06-13_dist3.txt};
  \addplot[smooth] file {../data/2014-06-13_dist4.txt};
  \draw ({axis cs:0.5,0}|-{rel axis cs:0,0}) -- ({axis cs:0.5,0}|-{rel axis cs:0,1});
%  \draw[decorate,decoration={brace,amplitude=15pt},rotate=90] (12.5,0)--(0,0) node {};
% Here should be a working underbrace 
  \end{axis}
 % \put(0,1){$\underbrace{\hspace{3.65cm}}_{A}$}
\end{tikzpicture}

\label{fig:2014-06-13_ex1plot}
\end{figure}

We are now looking for a set of values for which our response will be \emph{yes}. This is called the response strategy.

Formally $\text{if } x\in A \text{ then YES else NO}$

Our response strategy should not only depend on the probabilities, but also on the cost of being wrong.

\paragraph{Losses}

The loss function $L(S,R)$ is given by the following table.

\setlength{\extrarowheight}{.2cm}
\begin{tabular}{ c|c|c|}
  \backslashbox{\small Result}{\small Signal}       & \multicolumn{1}{c}{S = yes}   & \multicolumn{1}{c}{S = no} \\ \hline
  \multicolumn{1}{l|}{R = yes}  & $C_H$      & $C_{FA}$          \\ \hline
\multicolumn{1}{l|}{R = no}  & $C_M$    & $C_{CR}$    \\ \hline
\end{tabular}

\paragraph{Probabilities}

\begin{align}
P(H) &= \int_A p(X \mid S=yes)dx &= P(R=y \mid S=y) \\
P(FA) &= \int_A p(X \mid S=no)dx &= P(R=y \mid S=n) \\
P(M)  &= 1 - P(H) &= P(R=n \mid S=y)\\
P(CR) &= 1 - P(FA) &= P(R=n \mid S=n)
\end{align}

\paragraph{Idea: Minimize expected loss }

\begin{gather*}
E(L(S=y,R)) = P(H) \times C_H +  \underbrace{P(M)}_{1-P(H)} \times C_M \\
E(L(S=n,R)) = P(FA) \times C_{FA} +  \underbrace{P(CR)}_{1-P(FA)} \times C_{CR} \\
\text{Shorthand} \\
\pi_y = P(S=y) \\
\pi_n = P(S=n)
\end{gather*}

\begin{align*}
E(L(S,R)) &= \pi_y  E(L(S=y, R)) + \pi_n E(L(S=n, R)) &= \\
&= \pi_y C_H  P(H) + \pi_y C_M - \pi_y C_M P(H) + \pi_n C_{CR} - \pi_n C_{CR} P(FA) + \pi_n C_{FA} P(FA) &= \\
&= \pi_y P(H) (C_H - C_M) + \pi_n P(FA) (C_{FA} - C_{CR}) + \underbrace{(\pi_y C_M + \pi_n C_{CR})}_{\text{independent of } A} &
\end{align*}

Now we minimize only the parts dependent on $A$.

\begin{align*}
& \pi_y P(H) (C_H - C_M) + \pi_n P(FA) (C_{FA} - C_{CR}) &= \\
&= \pi_y \left(\int_A p(X \mid S=yes) dx\right)(C_H - C_M) + \pi_n \left(\int_A p(X \mid S=no) dx\right) (C_{FA} - C_{CR}) &= \\
&= \int_A \left[\pi_y p(X \mid S=yes)(C_H - C_M) + \pi_n p(X \mid S=no)(C_{FA} - C_{CR}) dx\right] & \\
\end{align*}

Choose $A$ such that we only integrate over the negative part.

\begin{align*}
\pi_y p(X \mid S=yes)(C_H - C_M) + \pi_n p(X \mid S=no)(C_{FA} - C_{CR}) &< 0 \\
\pi_y p(X \mid S=yes)(C_H - C_M) &\leqq - \pi_n p(X \mid S=no)(C_{FA} - C_{CR}) \\
\pi_y p(X \mid S=yes)(C_H - C_M) &\leqq \pi_n p(X \mid S=no)(C_{CR} - C_{FA}) \\
\end{align*}
\begin{equation}
\underbrace{\frac{\pi_y p(X \mid S=yes)}{\pi_n p(X \mid S=no)}}_\text{posterior odds} \geqq \underbrace{\frac{C_{CR} - C_{FA}}{C_H - C_M}}_\text{costs threshold}
\end{equation}

Interpretation: We choose $A$ so that the posterior odds are greater then the costs.

Other way of writing:

\begin{equation}
\underbrace{\frac{p(X \mid S=yes)}{p(X \mid S=no)}}_\text{likelihood ratio} \geqq \underbrace{\frac{\pi_n(C_{CR} - C_{FA})}{\pi_y(C_H - C_M)}}_\beta
\end{equation}


\paragraph{Examples Gaussian}

We can model the probability of Hits and False Alarms with Gaussians respectively:

\begin{align*}
  P\left(X|s=yes\right) &= \frac{1}{\sqrt{2\pi \sigma^2}} \cdot e^{-\frac{1}{2}\frac{\left(x-\mu_y\right)^2}{\sigma^2}}\\
  P\left(X|s=no\right) &= \frac{1}{\sqrt{2\pi \sigma^2}} \cdot e^{-\frac{1}{2}\frac{\left(x-\mu_n\right)^2}{\sigma^2}}
\end{align*}

Then by taking the log-likelihood ratio we can calculate when we say yes:

\begin{align*}
 \frac{1}{2}\sigma^2 \cdot \left[\left(x-\mu_y\right)^2 - \left(x-\mu_n\right)^2 \right] &\geq log\left(\beta\right)\\
  x^2 - 2x\mu_y + \mu_{y}^{2} - x^2 - 2x\mu_n + \mu_{n}^{2} &\leq - 2\sigma^2 \cdot log\left(\beta\right)\\
  2x\left(\mu_n - \mu_y\right)+\mu_{y}^{2}-\mu_{n}^{2}&\leq -2\sigma^2\cdot log\left(\beta\right)\end{align*}
  
By convention the mean of the noise distribution $\mu_n$ is smaller than $\mu_y$, such that the inequality turns and we get:

\begin{align*}
  x  &\geq \underbrace{\frac{-2\sigma^2 \cdot log\left(\beta\right) + \mu_{n}^{2}-\mu{n}^{2}}{2\left(\mu_n-\mu_y\right)}}_{\Theta}
\end{align*}

That we can interpret such that we answer with yes in the case the x we perceive is bigger than the threshold (criterion) $\Theta$.
In the case of $\beta = 1$ and equal prior probabilities that means:

\begin{align*}
  x \geq \frac{\left(\mu_n-\mu_y\right)\cdot \left(\mu_n+\mu_y\right)}{2\left(\mu_n-\mu_y\right)}
\end{align*}
i.e. the best threshold is just in the middle of the two Gaussians.

\subsection{Signal to Noise Ratio}

Now we want to find the limits of perception - how few light can we detect, or in other words: What is a persons signal to noise ratio for light detection.
The signal to noise ratio is defined as:

\begin{align*}
SNR = \frac{\mu_y-\mu_n}{\sigma}  
\end{align*} 

As we want to know the actual percept of a subject and not his decision-criterion when to say yes, we have to come up with a measure independent of the subjects threshold.
Receiver operator characteristics (ROC) allow for that by systematically varying the threshold, such that all possible criteria are covered (from always saying yes, to always saying no). Then we get a curve describing the perception of a subject independently of his criteria.



\begin{tikzpicture}
  \begin{axis}[axis x line*=bottom, axis y line*=left, enlargelimits=upper, axis on top, domain=0:1, legend style={at={(1.2,0.8)}, anchor=east,xlabel ={P(FA)}, ylabel={P(H)}}]
  \addplot[smooth] file {../data/2014-06-13_dist5.txt};
  \addlegendentry{ROC}
  \end{axis}
\end{tikzpicture}

 
\end{document}
